\chapter{\label{ch:intro}Intro}

\begin{frontquote}{The King of Hearts, \emph{Alice in Wonderland}}
``Begin at the beginning,'' the King said, very gravely, ``and go on till you come to the end: then stop.''
\end{frontquote}

\dropcap{A}{s} our ability to resolve physical systems grows, so, too, do our demands of the models we build.
Unfortunately, we rapidly approach an age where approximate analytic descriptions of physical systems simply cannot recover important features in systems of interest.
Substituting \emph{numerical}---i.e.\ \emph{in silico}---techniques into higher resolution models alleviates this problem somewhat (particularly as computer hardware evolves ``below'' the model), though the computational overhead of \naive\ algorithms limits their utility beyond nearly analytic calculations, particularly in multiscale or multiphysics applications.
Computational scientists, then, have a tricky job: they must have expertise in their own domain so as to begin formulating testable hypotheses about the (multi-)physical systems, as well as expertise in ``computation'' to understand the constraints inherent in exploring such hypotheses numerically.

\section{Active media}

Active media---dynamical systems that couple together through radiative processes---encompass a large class of problems across length and time scales and exhibit behavior fundamentally different from their passive counterparts.
These behaviors offer new avenues towards novel device designs, though engineering devices to exploit them presents a considerable challenge.
In particular, the underlying dynamical nature of active systems makes them inherently nonlinear, and accounting for these dynamics alongside the radiative coupling requires a multiphysical approach.
As such, this thesis primarily concerns itself with the development of computational techniques for use in modeling active systems both efficiently and accurately with a particular focus on acoustophoresis (acoustically-induced motion) and quantum optics.

\subsection{Acoustophoresis}

% First, explain the background/why is this interesting?
The placement of biological material or microscopic objects plays a large role in a number of technological applications related to biosensing.
For example, droplet-based microfluidics entails the careful construction, manipulation, and sensing of \si{\micro\liter} (or smaller) droplets of fluid for myriad lab-on-a-chip applications.
Similarly, DNA microarrays employ large numbers of micron-sized spots---each filled with a particular DNA sequence---to perform an experiment on thousands of genes simultaneously.
Manipulating individual droplets and fabricating a microarray both require careful placement of apparatus; though, given the small length scale of these problems, conventional manipulation techniques (such as pipetting) become problematic.
Instead, researchers require alternative means of precisely controlling the motion of such objects.

% This site is really great: http://bme.lth.se/research-pages/nanobiotechnology-and-lab-on-a-chip/research/acoustophoresis/
Because of their low energy and minimal invasiveness, so-called acoustic tweezers offer an ideal mechanism for precise microscopic positioning in both biological and nonbiological applications.
By varying the pressure in the surrounding environment through the precise application of ultrasonic pulses, acoustic tweezers effect acoustophoresis for a variety of purposes including object placement, fractionation~\cite{Petersson2007}, and flow shaping.
% Next, explain the specific problem
Present models of such systems often fail to account for multiple scattering events or do so only by way of time- or volume-averaged techniques.
This poses a significant problem in extremely small systems where such effects necessarily become important.
% Finally, tease how we solved it
To overcome this, \cref{ch:bubbles} develops the machinery to simulate the motion of an ensemble of hard spheres within a fullwave scattering framework.

\subsection{Light in disordered media}

Disordered nanostructures give rise to striking optical phenomena.
\emph{Cyphochilus} spp.\ beetles, for instance, owe their intense white coloration to an aperiodic arrangement of scales that scatters light across wavelengths~\cite{Vukusic2007}.
Whereas manmade objects of similar whiteness and intensity require structures as thick as \SI{100}{\micro\meter}, the scales of \emph{cyphochilus} spp.\ can span as few as \SI{4}{\micro\meter} by exploiting an interior structure of disordered filaments.
Additional effects such as Anderson localization~\cite{Anderson1985}---wherein light remains spatially confined for extended periods of time---and L\'evy flights~\cite{Barthelemy2008}---in which light experiences superdiffusive, i.e.\ superlinear (in time), behavior---all follow from similarly disordered structures.
Because of their dynamical absorption and emission effects, these phenomena all fall under the broad category of active light/matter interactions.

Quantum dots---colloquially called ``tuneable atoms'' because of the ease with which engineers can manipulate their spectra---stand as a premier element in modern optoelectronic devices and have enjoyed widespread success in areas such as light harvesting and quantum information storage/retrieval.
Because of this, a number of analytic methods based on ensemble-averaged single particle and higher order Green's functions have arisen to describe light propagation in such systems.
These methods essentially cast the active quantum system as a homogeneous continuum source in the governing electromagnetic equations (Maxwell's equations for semiclassical systems)~\cite{Arecchi1965}, though such a treatment cannot account for effects arising from long-range order, partial order, or anisotropies.
Models of these effects, then, require a detailed computational framework that captures scattering/radiation effects between discrete, disordered elements.
In \cref{ch:quantum dots} we develop just such a framework; one that eschews a phenomenological treatment of matter, preferring instead to ``generate'' the constituative relations that govern the sources in Maxwell's equations.

\section{Numerical simulation of wave propagation}

\begin{figure}
  \centering
  \input{figures/de_ie_mindmap}
  \caption{\label{fig:mindmap} Comparison of differential-equation and integral-equation methodologies.
    As both approaches have several advantages and disadvantages, the choice of which technique to use largely depends on the problem under consideration.
  }
\end{figure}

Wave phenomena influence every aspect of our lives across every scale of the universe, thus it should come as little surprise that techniques to explore and analyze these phenomena lie at the heart of many scientific and engineering disciplines.
Broadly, these techniques fall into differential-equation-based and integral-equation-based categories with each having several benefits and drawbacks.
Differential-equation-based models have a large, sparse character that follows directly from a discretization of the wave equation throughout a volume of interest.
Such a volumetric discretization explicitly describes fields within the entirety of the simulation domain and works well to capture cavity effects or effects involving variations in material parameters.
Open systems where waves propagate ``to infinity'' require significant care, however, and employ corrections such as perfectly-matched layers~\cite{Berenger1994} or absorbing boundary conditions~\cite{Mur1981} to approximate correct asymptotic behavior.

Integral-equation-based methods, on the other hand, remedy many of the problems associated with differential methods.
By employing a Green's function to directly determine the response of interacting sources, these methods automatically capture radiation boundary conditions and eliminate the numerical issues associated with intermediate meshes entirely.
These features, however, do not come without cost.
Integral-equation methodologies have a great deal more mathematical sophistication than their differential-equation analogues and their discretizations inherently produce dense interaction matrices.
The $\mathcal{O}(n^2)$ solution cost of these matrices scales poorly for systems with many degrees of freedom, thus a large body of work has emerged to reduce this cost to $\mathcal{O}(n^p)$ (where $p < 2$) or even $\mathcal{O}(n \log n)$.
These so-called ``fast methods'' exploit the underlying structure of the interaction matrix to develop compressed representations of the interaction between distant sources with fully-controllable numerical error.
Because of its accuruacy and speed, the development of such a method stands as the principal contribution of \cref{ch:accelerator}.
