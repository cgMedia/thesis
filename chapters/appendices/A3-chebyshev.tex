\chapter{Chebyshev polynomials}

\begin{figure}[h]
  \centering
  \conditionalFigureInput{figures/chebyshev_polynomials}
  \caption{\label{fig:chebyshev polynomials} Chebyshev polynomials $T_0(x)$ through $T_6(x)$.
    The roots of $T_{m + 1}(x)$ give the sample points for an interpolation scheme of order $m$ on the interval $\qty[-1, 1]$.
  }
\end{figure}

The Chebyshev polynomials of the first kind, defined by
\begin{equation}
  T_n(x) = \cos(n \arccos(x))
  \label{eq:chebyshev}
\end{equation}
and shown in \cref{fig:chebyshev polynomials}, form an orthogonal (though not orthonormal) sequence well-suited to interpolation.
These polynomials have a continuous orthogonality relation over the interval $-1 \leqslant x \leqslant 1$ with respect to $w(x) = \qty(1-x^2)^{-1/2}$, giving
\begin{equation}
  \int_{-1}^1 \frac{T_i(x) T_j(x)}{\sqrt{1 - x^2}} \dd{x} =
  \begin{cases}
    0 & i \not = j \\
    \pi / 2 & i = j \not = 0 \\
    \pi & i = j = 0
  \end{cases} \label{eq:continuous orthogonality} \\
\end{equation}
Such an orthogonality motivates $\qty{T_k(x)\, : \, k = 0, 1, \ldots, m}$ as a basis for $\mathbb{P}^m$---the polynomials through order $m$---on the interval $-1 \leqslant x \leqslant 1$.
To construct a polynomial interpolation of an arbitrary function $f(x)$ in this basis such that
\begin{equation}
  \begin{aligned}
    f(x) &\approx P_m(x) \\
    &\equiv \sum_{i = 0}^{m} c_i T_i(x),
  \end{aligned}
  \label{eq:chebyshev expansion}
\end{equation}
we require samples of the function at $m+1$ interpolation nodes\footnote{For convenience, Latin letters index \emph{functions} while Greek letters index \emph{points}.} $\qty{x_\lambda \,:\, \lambda = 0, 1, \ldots, m}$ where $f(x_\lambda) = P_m(x_\lambda)$.
By choosing sample points corresponding to Chebyshev nodes,
\begin{equation}
  x_\lambda = -\cos(\frac{\pi (\lambda + 1/2)}{m + 1}) \qquad \lambda = 0, 1, 2, \ldots, m,
\end{equation}
the Chebyshev polynomials satisfy~\cite{Gil2007}
\begin{equation}
  \begin{aligned}
    \sum_{\lambda = 0}^{m} T_i(x_\lambda) T_j(x_\lambda) &=
    \begin{cases}
      0 & i \not = j \\
      (m + 1)/2 & i = j \not = 0 \\
      m + 1 & i = j = 0
    \end{cases} \\
  \end{aligned}
  \label{eq:discrete orthogonality}
\end{equation}
in addition to the continuous relationship in \cref{eq:continuous orthogonality}.
Inserting \cref{eq:chebyshev expansion} into \cref{eq:discrete orthogonality} then gives
\begin{equation}
  \sum_{\lambda = 0}^{m} T_i(x_\lambda) f(x_\lambda) = \sum_{\lambda = 0}^{m}T_i(x_\lambda) P_m(x_\lambda) = \sum_{i = 0}^m c_i \sum_{\lambda = 0}^{m}T_i(x_\lambda) T_i(x_\lambda)
\end{equation}
thus
\begin{equation}
  c_i = \frac{\alpha_i}{m + 1} \sum_{\lambda = 0}^{m}T_i(x_\lambda) f(x_\lambda) \qquad \alpha_i = 2 - \delta_{i 0}.
  \label{eq:chebyshev coefficient}
\end{equation}
Finally, having obtained a Chebyshev approximation of $f(x)$ on the interval $-1 \leqslant x \leqslant 1$, we may effect a Chebyshev approximation of $f(x)$ on the interval $a \leqslant x \leqslant b$ by letting
\begin{equation}
  y \equiv \frac{x - (b + a)/2}{(b-a)/2}
\end{equation}
and constructing a Chebyshev approximation in $y$.

\begin{figure}
  \centering
  \conditionalFigureInput{figures/interpolation_comparison}
  \caption{\label{fig:pathological interpolation} Interpolation of a pathological function, $f(x) = \qty(1 + 16x^2)^{-1/2}$, using Chebyshev and equally-spaced Lagrange interpolation schemes.
  Because the Chebyshev scheme clusters sample points in the tails of the interpolation window, it does not suffer from high-order ringing effects (Runge's phenomenon).}
\end{figure}

\section{Notes on the Chebyshev polynomials}

\subsection{Derivatives}
The Chebyshev polynomials provide two means of approximating $f'(x)$ given samples of $f(x)$ though both have numerical drawbacks.
Given that we wish to repeatedly evaluate the interpolating polynomial at a collection of static points, it becomes prudent to pre-evaluate and cache $T_i(x)$ in \cref{eq:chebyshev expansion} for speed.
The recurrence
\begin{equation}
  \qty(1 - x^2) T_n'(x) = n \qty[T_{n-1}(x) - x T_n(x)]
  \label{eq:derivative recurrence}
\end{equation}
analytically relates Chebyshev polynomials to their derivatives, and so we may equivalently cache $T'_n(x)$ to repeatedly evaluate a derivative.
Unfortunately, this becomes problematic for $x \to \pm 1$ as the $1-x^2$ term can cause a catastrophic loss of precision due to division by (near) zero.
Instead,
\begin{equation}
  c'_{i-1} = c'_{i+1} + 2 i c_i \qquad c'_{m+1} = c'_m = 0
\end{equation}
adjusts the Chebyshev coefficients to give an approximated derivative in terms of the original basis.
While this expression does not suffer from numerical cancellation issues, it incurs a large amount of overhead when evaluating many approximations.
Moreover, this overhead grows significantly in higher-dimensional systems with vector derivatives.

In practice, \QuEST{} makes use of the former strategy of differentiating the ``evaluating functions'' though without the recurrence of \cref{eq:derivative recurrence}.
Instead, functions for the Chebyshev polynomials and their derivatives through a specified order, provide the necessary evaluations.
Moreover, these functions contain the requisite polynomials expressed in Horner form to improve both speed and precision~\cite{Knuth1997}.
While this method does not readily generalize to interpolations of arbitrary order (as it would require prohibitively long enumerations of functions), it nevertheless facilitates an efficient derivative evaluation without unduly sacrificing clarity.

\subsection{Higher-dimensional approximations}
The mechanics for constructing an approximation to $f(x)$ extend naturally to higher-dimensional and vector-valued systems.
In such systems, the Chebyshev approximation becomes a tensor polynomial, and the summations in \cref{eq:chebyshev expansion,eq:chebyshev coefficient} become mondo tensor contractions, i.e.
\begin{subequations}
  \begin{align}
    \vb{f}(\vb{r}) &\approx \vb{c}_{ijk} T_i(x) T_j(y) T_k(z), \\
    \vb{c}_{ijk} &= \frac{\alpha_{ii'} \alpha_{jj'} \alpha_{kk'}}{\qty(m+1)^3} T_{ii'}(x_\lambda) T_{jj'}(y_\mu) T_{kk'}(z_\nu) \vb{f}(x_\lambda, y_\mu, z_\nu) \label{eq:mondo tensor}
  \end{align}
\end{subequations}
with an implied summation over the bound indices $i'$, $j'$, $k'$ and $\lambda$, $\mu$, $\nu$.
\QuEST{} makes use of the Tensor Algebra Compiler (taco)~\cite{taco} to generate the equivalent source expression for \cref{eq:mondo tensor}.
